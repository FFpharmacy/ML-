# 学习笔记二
## 目录
* 补坑
* 任务二
---

# 补坑
## 1.F1_SCORE

![confuse matrix](https://github.com/FFpharmacy/machine-learning/assets/142389885/5e17db14-fb2b-4aa9-af08-d010d3d7e2c1)

### 准确率(accuracy)
所有预测正确的样本占总样本的比例

![accuracy](https://github.com/FFpharmacy/machine-learning/assets/142389885/5434d5a2-5025-4745-a2c1-b6bfcceae061)

### 精确率(precision)
预测为正的样本中预测正确的比例


![precision](https://github.com/FFpharmacy/machine-learning/assets/142389885/24f271f3-05f1-40f7-a019-1ff249fcbfde)
> 精确率代表对正样本结果中的预测准确程度，准确率则代表整体的预测准确程度，包括正样本和负样本。
Precision是针对预测结果而言的。预测结果中，预测为正的样本中预测正确的概率。宁愿漏掉犯人，不能抓错好人

### 召回率（recall）
预测为正的正例占全部实际为正例的样本 （可能将实际正例预测为正例即真正例TP，也可能实际正例预测为负例即假负例FN）的比例（真正正确的占所有实际为正的比例）

![recall](https://github.com/FFpharmacy/machine-learning/assets/142389885/84bd09a8-fda7-48f6-8280-f63488b93df0)
> 这里presicion应为recall

Recall是针对数据样本而言的。数据样本中，正样本中预测正确的概率。宁愿错杀一千，不能放过一个。

### F1_SCORE
F-score 是一种用于评估二分类模型性能的指标，分别从两个角度，结合了模型的精确度（Precision）和召回率（Recall），主观（Predicted）和客观（Recall）上去综合的分析TP够不够大，帮助我们综合考虑模型的预测准确性和对正样本的捕捉能力。
* FP/TP影响的是主观判断上TP够不够分量，也就是主观上TP这个值到底够不够大
* FN/TP影响的是客观判断上TP够不够分量，也就是客观上TP这个值到底够不够大
 <img width="371" alt="截屏2023-08-17 下午7 35 54" src="https://github.com/FFpharmacy/machine-learning/assets/142389885/61e6bc1d-79e9-4532-906e-2bf5b8b1b7a0">

> F1即为P和R的调和平均数

精确率和召回率互相影响，理想状态下肯定追求两个都高，但是实际情况是两者相互“制约”：
追求精确率高，则召回率就低；追求召回率高，则通常会影响精确率。(和type1,type2 error相似)
我们当然希望预测的结果精确率越高越好，召回率越高越好， 但事实上这两者在某些情况下是矛盾的。

  <img width="591" alt="截屏2023-08-17 下午7 33 43" src="https://github.com/FFpharmacy/machine-learning/assets/142389885/7847fc76-bc98-4a24-b775-9a76eefc0281">

这样就需要综合考虑它们，最常见的方法就是F-score。 也可以绘制出P-R曲线图，观察它们的分布情况。

<img width="1130" alt="截屏2023-08-17 下午7 39 00" src="https://github.com/FFpharmacy/machine-learning/assets/142389885/9be5a6b2-d9d7-4e86-8508-6d9363dd2e84">

* F-score = 0 (实际上是无限趋近于0)
主观上TP很小 OR 客观上TP很小
即 FP 或 FN 远大于TP，这里做极限假设我们可以知道F-score趋近于0

* F-score = 1
主观上和客观上来说TP都很大，也就是FP和FN都等于0（下限）。


  




